
# 

母集団、全数調査、標本、標本抽出、無作為抽出

n個のデータ $x_1,\cdot,x_n$ が標本として抽出される。n標本の大きさ。

母集団に確率モデルを想定し、その確率分布に従う確率変数の実現値としてデータを捉える。
確率変数 $X_1$ 実現値の x_1であり。

X_1,..X_n　互いに独立に同一分布に従う。各X_iが同一の確率分布Fに従うことを意味する。

データx_1,\cdot,x_nを確率変数の

記述統計：データからヒストグラムを描いたり、平均、分散などを計算して母集団の特性を調べる。

推測統計：母集団に確率モデルを想定し、その確率分布に従う確率変数の実現値としてデータを捉える。

$\bar X=\frac{1}{n}\sum_{i=1}^{n}X_i$

$S^2=\frac{1}{n}\sum_{i=1}^{n}(X_i-\bar x)^2$


$E[X_i]=\mu$

$Var[X_i]=\sigma^2$

**母平均、母分散**：母集団の平均と分散、　$\mu$ 、$\sigma^2$

**標本平均、標本分散**：　標本に基づいて計算した平均と分散。

$\bar X=\frac{1}{n}\sum_{i=1}^{n}X_i$

$S^2=\frac{1}{n}\sum_{i=1}^{n}(X_i-\bar X)^2$

**統計量**：$\bar X$, $S^2$のような、標本に基づいた関数を統計量といい。その確率分布を標本分布という。

統計量の確率分布を標本分布といい。

$\bar X$の平均と分散は計算できるが、その確率分布を求めることは困難である。

平均が \mu分散が\sigma^2の母集団からランダムサンプリングして

標本平均の平均と分散：

$E[\bar X]=\mu$

$Var[\bar X]=\frac{\sigma^2}{n}$




となる。

標本平均の推定誤差はnとともに小さくなることを示している。

S^2の期待値：

$E[S^2]={(n-1)/n}\sigma^2$

S^2の期待値は　$\sigma^2$　にならない。
期待値が $\sigma^2$ になるために、 $\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar X)^2$

### 分散の期待値求める？

**不偏性**: とは、推定量の期待値が、真の母数の値となることです。

**不偏分散**: $V^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar X)^2$

の期待値が　$\sigma^2$となる。これを不偏分散という。


## 正規母集団からの代表的な標本分布



定理：

正規母集団から
$X_1, X_n$をランダムサンプルとする

- $\bar X$, $V^2$は独立に分布する
- $\bar X ~ N(\mu, \sigma^2 / n)$
- $(n-1)V^2/\sigma^2~ X^2_{n-1}$


- t-分布
- F-分布
- カイ二乗分布

**t-分布**:

正規母集団　$X_1, X_n$　をランダムサンプルとする

確率変数 $Z=\sqrt{n}(\bar X - \mu)/\sigma$ は標準正規分布　$N(0,1)$ に従う。

\sigma　の代わりにVを代入した確率変数

$T=\sqrt{n}(\bar X - \mu)/V$ より裾厚い分布になっている。

$U=(n-1)V^2/\sigma^2$, $U  \chi_m^2$

$T=Z/\sqrt{U/(n-1)}$

ZとUを独立な確率変数とし、$Z \sim N(0,1), U \sim \chi_m^2$とするとき、

$T=Z/\sqrt{(U/m)}$
は自由度mのスチューデントのt分布に従うといい

コーシー分布


F-分布：$T^2=Z^2/(U/m)$　Tは自由度(1,m)のF分布に従うことがわかる。
分散の同等性検定や線形回帰モデルの説明変数の選択に関する仮説検定などで用いられる。

SとTを独立な確率変数とし、 S~\chi_m^2 T~\chi_n^2とする、確率変数Yを

$Y=\frac{S/m}{T/n}$

Yは自由度 (m,n) のスネデッカーのF分布。

確率変数と確率分布の収束

確率収束　$\lim_{n \rightarrow \infty} P(|U_n-U| \ge \epsilon)=0$ $U_n-> pU$　で表す。

**マルコフの不等式**: Yを非負の確率変数で　E[Y]<\infty　とする、この時任意の　c>0 に対して、次の不等式が成り立つ：

$P(Y\ge c) \le E[Y]/c$

**チェビシェフの不等式**:

 任意の確率変数 $Z$ と正の実数 $\epsilon$ に対して $P\{|Z-E(z)| \ge \epsilon\} \le \frac{V(Z)}{\epsilon^2}$  |

**大数の弱法則** | 任意の正の実数 $\epsilon$ に対して $P(|\frac{1}{n}\sum_{i=1}^n{X_i}- \mu | \ge \epsilon) -> 0 (n-> \infty)$ | 平均値が期待値に近づいていくことを意味している

**中心極限定理** | 任意実数xに対して $P() -> \int_{-\infty}^x \frac{1}{\sqrt(2\pi)}e^{-t^2}$ |



